{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Religious Toxic Classification Re-implementation\n",
                "\n",
                "This notebook provides a complete pipeline for identifying toxic comments directed at religious identity groups using **DeBERTa-v3** with custom architectural enhancements."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, Subset\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    set_seed,\n",
                "    DataCollatorWithPadding\n",
                ")\n",
                "from transformers.modeling_outputs import SequenceClassifierOutput\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, f1_score, precision_score, recall_score, \n",
                "    jaccard_score, hamming_loss, roc_auc_score, classification_report\n",
                ")\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "# --- Configuration ---\n",
                "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
                "MAX_LENGTH = 256\n",
                "EPOCHS = 10\n",
                "PER_DEVICE_BATCH_SIZE = 8\n",
                "GRAD_ACCUM_STEPS = 2\n",
                "LEARNING_RATE = 2e-5\n",
                "METRIC_FOR_BEST_MODEL = 'eval_micro_f1'\n",
                "VALIDATION_SPLIT_SIZE = 0.2\n",
                "SEED = 42\n",
                "\n",
                "set_seed(SEED)\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "RELIGION_COLS = ['christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion']\n",
                "TEXT_COL = 'comment_text'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading and Preprocessing\n",
                "\n",
                "We filter the dataset for religious toxicity and apply oversampling to balance the classes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def filter_and_binarize(df, target_cols, min_toxicity=0.5):\n",
                "    valid_target_cols = [col for col in target_cols if col in df.columns]\n",
                "    if not valid_target_cols: return pd.DataFrame()\n",
                "    df_filled = df.fillna({col: 0 for col in valid_target_cols})\n",
                "    toxic_mask = df_filled[valid_target_cols].ge(min_toxicity).any(axis=1)\n",
                "    filtered = df_filled.loc[toxic_mask, [TEXT_COL] + valid_target_cols].copy()\n",
                "    filtered[valid_target_cols] = (filtered[valid_target_cols] >= min_toxicity).astype(int)\n",
                "    return filtered.dropna(subset=[TEXT_COL]).reset_index(drop=True)\n",
                "\n",
                "def balance_multilabel_df(df, target_cols):\n",
                "    from sklearn.utils import resample\n",
                "    dfs = []\n",
                "    max_count = df[target_cols].sum().max()\n",
                "    for col in target_cols:\n",
                "        df_pos = df[df[col] == 1]\n",
                "        df_neg = df[df[col] == 0]\n",
                "        dfs.append(pd.concat([\n",
                "            resample(df_pos, replace=True, n_samples=max_count, random_state=SEED),\n",
                "            resample(df_neg, replace=False, n_samples=max_count, random_state=SEED)\n",
                "        ]))\n",
                "    return pd.concat(dfs).drop_duplicates().reset_index(drop=True)\n",
                "\n",
                "print(\"Loading data...\")\n",
                "if os.path.exists(\"train.csv\"):\n",
                "    df_original = pd.read_csv(\"train.csv\")\n",
                "    religion_df = balance_multilabel_df(filter_and_binarize(df_original, RELIGION_COLS), RELIGION_COLS)\n",
                "    print(f\"Total samples: {len(religion_df)}\")\n",
                "else:\n",
                "    print(\"Error: train.csv not found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Architecture\n",
                "\n",
                "We implement a custom model with **Focal Loss**, **Hierarchical Attention**, and **Adaptive Pooling**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FocalLoss(nn.Module):\n",
                "    def __init__(self, gamma=2.0): \n",
                "        super().__init__()\n",
                "        self.gamma = gamma\n",
                "    def forward(self, logits, targets):\n",
                "        probs = torch.sigmoid(logits).clamp(1e-6, 1.0 - 1e-6)\n",
                "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
                "        return (-(1 - pt) ** self.gamma * torch.log(pt)).mean()\n",
                "\n",
                "class HierarchicalAttentionLayer(nn.Module):\n",
                "    def __init__(self, hidden_size, num_heads): \n",
                "        super().__init__()\n",
                "        self.attn = nn.MultiheadAttention(hidden_size, num_heads, batch_first=True)\n",
                "        self.proj = nn.Linear(hidden_size * 2, hidden_size)\n",
                "        self.norm = nn.LayerNorm(hidden_size)\n",
                "    def forward(self, x, mask=None):\n",
                "        m = (mask == 0) if mask is not None else None\n",
                "        a, _ = self.attn(x, x, x, key_padding_mask=m)\n",
                "        return self.norm(F.dropout(self.proj(torch.cat([x, a], -1)), 0.1) + x)\n",
                "\n",
                "class AdaptivePoolingClassifier(nn.Module):\n",
                "    def __init__(self, hidden_size, num_labels):\n",
                "        super().__init__()\n",
                "        self.dense = nn.Linear(hidden_size * 4, hidden_size)\n",
                "        self.out = nn.Linear(hidden_size, num_labels)\n",
                "        self.attn_proj = nn.Linear(hidden_size, 1)\n",
                "    def forward(self, x, mask=None):\n",
                "        m = mask.unsqueeze(-1).float()\n",
                "        cls_p = x[:, 0]\n",
                "        mean_p = (x * m).sum(1) / m.sum(1).clamp(1e-9)\n",
                "        max_p = (x + (1-m)*-1e9).max(1)[0]\n",
                "        w = F.softmax(self.attn_proj(x).masked_fill(mask.unsqueeze(-1)==0, -1e9), 1)\n",
                "        attn_p = (w * x).sum(1)\n",
                "        return self.out(F.dropout(F.gelu(self.dense(torch.cat([cls_p, mean_p, max_p, attn_p], -1))), 0.1))\n",
                "\n",
                "class CustomDebertaV3ForMultilabel(AutoModelForSequenceClassification):\n",
                "    def __init__(self, config):\n",
                "        super().__init__(config)\n",
                "        self.loss_fct = FocalLoss()\n",
                "        self.hierarchical_attention = HierarchicalAttentionLayer(config.hidden_size, config.num_attention_heads)\n",
                "        self.adaptive_classifier = AdaptivePoolingClassifier(config.hidden_size, config.num_labels)\n",
                "        if hasattr(self, 'classifier'): del self.classifier\n",
                "        if hasattr(self, 'pooler'): del self.pooler\n",
                "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
                "        x = self.deberta(input_ids, attention_mask=attention_mask, **kwargs)[0]\n",
                "        logits = self.adaptive_classifier(self.hierarchical_attention(x, attention_mask), attention_mask)\n",
                "        loss = self.loss_fct(logits, labels) if labels is not None else None\n",
                "        return SequenceClassifierOutput(loss=loss, logits=logits)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training and Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ToxicCommentsDataset(Dataset):\n",
                "    def __init__(self, texts, labels, tokenizer, max_length):\n",
                "        self.texts, self.labels, self.tokenizer, self.max_length = texts, labels, tokenizer, max_length\n",
                "    def __len__(self): return len(self.texts)\n",
                "    def __getitem__(self, i):\n",
                "        e = self.tokenizer(str(self.texts[i]), max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
                "        return {'input_ids': e['input_ids'].flatten(), 'attention_mask': e['attention_mask'].flatten(), 'labels': torch.tensor(self.labels[i], dtype=torch.float)}\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "ds = ToxicCommentsDataset(religion_df[TEXT_COL].values, religion_df[RELIGION_COLS].values, tokenizer, MAX_LENGTH)\n",
                "tr_idx, val_idx = train_test_split(range(len(ds)), test_size=VALIDATION_SPLIT_SIZE, random_state=SEED)\n",
                "\n",
                "model = CustomDebertaV3ForMultilabel.from_pretrained(MODEL_NAME, num_labels=len(RELIGION_COLS)).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "args = TrainingArguments(output_dir='./results', num_train_epochs=EPOCHS, per_device_train_batch_size=PER_DEVICE_BATCH_SIZE, gradient_accumulation_steps=GRAD_ACCUM_STEPS, learning_rate=LEARNING_RATE, evaluation_strategy=\"epoch\", load_best_model_at_end=True, metric_for_best_model=METRIC_FOR_BEST_MODEL, report_to='none')\n",
                "\n",
                "trainer = Trainer(model=model, args=args, train_dataset=Subset(ds, tr_idx), eval_dataset=Subset(ds, val_idx), data_collator=DataCollatorWithPadding(tokenizer))\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Threshold Tuning and Final Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preds = trainer.predict(Subset(ds, val_idx))\n",
                "probs = torch.sigmoid(torch.tensor(preds.predictions)).numpy()\n",
                "true = religion_df.iloc[val_idx][RELIGION_COLS].values\n",
                "\n",
                "best_t, best_f1 = 0.5, -1\n",
                "for t in np.arange(0.05, 0.95, 0.01):\n",
                "    f1 = f1_score(true, (probs >= t).astype(int), average='micro', zero_division=0)\n",
                "    if f1 > best_f1: best_f1, best_thresh = f1, t\n",
                "\n",
                "print(f\"Best Threshold: {best_thresh:.4f}\")\n",
                "print(classification_report(true, (probs >= best_thresh).astype(int), target_names=RELIGION_COLS))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}